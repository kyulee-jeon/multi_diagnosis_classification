{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7198024d",
   "metadata": {},
   "source": [
    "# Import Module and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "683c4844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# Imports modules\n",
    "#########################################################\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D,Conv2D, Flatten\n",
    "from tensorflow.keras.layers import (Input, Conv1D, MaxPooling1D, Dropout, BatchNormalization, Activation, Add, Flatten, Dense)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b3c81a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = os.getcwd()\n",
    "my_dir = '/home/ubuntu/dr-you-ecg-20220420_mount/STEMI_JKL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61e6b59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17898, 5120, 8) (17898, 50)\n"
     ]
    }
   ],
   "source": [
    "whole_x = np.load('/home/ubuntu/dr-you-ecg-20220420_mount/STEMI_JKL/PTB_X_0616.npy')\n",
    "whole_y = np.load('/home/ubuntu/dr-you-ecg-20220420_mount/STEMI_JKL/PTB_Y_0616.npy')\n",
    "print(whole_x.shape, whole_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abf85e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>confirm_disease</th>\n",
       "      <th>filename_hr</th>\n",
       "      <th>1AVB</th>\n",
       "      <th>2AVB</th>\n",
       "      <th>3AVB</th>\n",
       "      <th>AFIB</th>\n",
       "      <th>AFLT</th>\n",
       "      <th>ALMI</th>\n",
       "      <th>...</th>\n",
       "      <th>NORM</th>\n",
       "      <th>NST_</th>\n",
       "      <th>PAC</th>\n",
       "      <th>PACE</th>\n",
       "      <th>PSVT</th>\n",
       "      <th>PVC</th>\n",
       "      <th>RAO_RAE</th>\n",
       "      <th>RVH</th>\n",
       "      <th>SEHYP</th>\n",
       "      <th>WPW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15709.0</td>\n",
       "      <td>['NORM']</td>\n",
       "      <td>records500/00000/00001_hr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>20372.0</td>\n",
       "      <td>['NORM']</td>\n",
       "      <td>records500/00000/00003_hr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>17014.0</td>\n",
       "      <td>['NORM']</td>\n",
       "      <td>records500/00000/00004_hr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>17448.0</td>\n",
       "      <td>['NORM']</td>\n",
       "      <td>records500/00000/00005_hr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>19005.0</td>\n",
       "      <td>['NORM']</td>\n",
       "      <td>records500/00000/00006_hr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ecg_id  patient_id confirm_disease                filename_hr  1AVB  2AVB  \\\n",
       "0       1     15709.0        ['NORM']  records500/00000/00001_hr     0     0   \n",
       "1       3     20372.0        ['NORM']  records500/00000/00003_hr     0     0   \n",
       "2       4     17014.0        ['NORM']  records500/00000/00004_hr     0     0   \n",
       "3       5     17448.0        ['NORM']  records500/00000/00005_hr     0     0   \n",
       "4       6     19005.0        ['NORM']  records500/00000/00006_hr     0     0   \n",
       "\n",
       "   3AVB  AFIB  AFLT  ALMI  ...  NORM  NST_  PAC  PACE  PSVT  PVC  RAO_RAE  \\\n",
       "0     0     0     0     0  ...     1     0    0     0     0    0        0   \n",
       "1     0     0     0     0  ...     1     0    0     0     0    0        0   \n",
       "2     0     0     0     0  ...     1     0    0     0     0    0        0   \n",
       "3     0     0     0     0  ...     1     0    0     0     0    0        0   \n",
       "4     0     0     0     0  ...     1     0    0     0     0    0        0   \n",
       "\n",
       "   RVH  SEHYP  WPW  \n",
       "0    0      0    0  \n",
       "1    0      0    0  \n",
       "2    0      0    0  \n",
       "3    0      0    0  \n",
       "4    0      0    0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_PTB = pd.read_csv('/home/ubuntu/dr-you-ecg-20220420_mount/STEMI_JKL/PTB_multi_label_220616.csv')\n",
    "df_PTB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29ff5e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['1AVB', '2AVB', '3AVB', 'AFIB', 'AFLT', 'ALMI', 'AMI', 'ANEUR',\n",
    "       'ASMI', 'BIGU', 'CLBBB', 'CRBBB', 'DIG', 'EL', 'ILBBB', 'ILMI',\n",
    "       'IMI', 'INJAL', 'INJAS', 'INJIL', 'INJIN', 'INJLA', 'IPLMI',\n",
    "       'IPMI', 'IRBBB', 'ISCAL', 'ISCAN', 'ISCAS', 'ISCIL', 'ISCIN',\n",
    "       'ISCLA', 'ISC_', 'IVCD', 'LAFB', 'LAO_LAE', 'LMI', 'LNGQT', 'LPFB',\n",
    "       'LVH', 'NDT', 'NORM', 'NST_', 'PAC', 'PACE', 'PSVT', 'PVC',\n",
    "       'RAO_RAE', 'RVH', 'SEHYP', 'WPW']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb572c1",
   "metadata": {},
   "source": [
    "# Data Preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8030e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (14318, 5120, 8) y_train:  (14318, 50)\n",
      "x_test:  (3580, 5120, 8) y_test:  (3580, 50)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(whole_x, whole_y, test_size = 0.2, random_state = 321)\n",
    "\n",
    "print('x_train: ',x_train.shape,'y_train: ', y_train.shape)\n",
    "print('x_test: ',x_test.shape, 'y_test: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2285f54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      167\n",
       "1        4\n",
       "2        2\n",
       "3       11\n",
       "4       16\n",
       "5       41\n",
       "6       27\n",
       "7        1\n",
       "8      311\n",
       "9        4\n",
       "10     106\n",
       "11     103\n",
       "12      27\n",
       "13       1\n",
       "14      15\n",
       "15      69\n",
       "16     206\n",
       "17      29\n",
       "18      43\n",
       "19       5\n",
       "20       3\n",
       "21       1\n",
       "22       7\n",
       "23       6\n",
       "24     204\n",
       "25     118\n",
       "26       7\n",
       "27      28\n",
       "28      28\n",
       "29      34\n",
       "30      18\n",
       "31     227\n",
       "32     154\n",
       "33     339\n",
       "34      50\n",
       "35       6\n",
       "36      25\n",
       "37      40\n",
       "38     208\n",
       "39     365\n",
       "40    1422\n",
       "41     117\n",
       "42       5\n",
       "43      41\n",
       "44      10\n",
       "45     205\n",
       "46      17\n",
       "47       9\n",
       "48       5\n",
       "49       9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_test = pd.DataFrame(y_test)\n",
    "df_y_test.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe61639",
   "metadata": {},
   "source": [
    "# Build Model\n",
    "---\n",
    "## Attia\n",
    "[reference]\n",
    "https://pseudo-lab.github.io/Tutorial-Book/chapters/time-series/Ch5-CNN-LSTM.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "220c2587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model():\n",
    "    inputs = tf.keras.Input(shape=(5120, 8))\n",
    "    \n",
    "    x = tf.keras.layers.Conv1D(filters=16, padding = 'same', kernel_size=7, activation='relu')(inputs)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPool1D(pool_size = 2)(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=16, padding = 'same', kernel_size=5, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPool1D(pool_size = 4)(x)                           \n",
    "    x = tf.keras.layers.Conv1D(filters=32, padding = 'same', kernel_size=5, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPool1D(pool_size = 2)(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=32, padding = 'same', kernel_size=5, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPool1D(pool_size = 4)(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=64, padding = 'same', kernel_size=5, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPool1D(pool_size = 2)(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=64, padding = 'same', kernel_size=3, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPool1D(pool_size = 2)(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=64, padding = 'same', kernel_size=3, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPool1D(pool_size = 2)(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=64, padding = 'same', kernel_size=3, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(filters=128, padding = 'same', kernel_size=12, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPool1D(pool_size = 2)(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(50, activation = 'softmax')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac5a22ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 5120, 8)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 5120, 16)          912       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 2560, 16)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 2560, 16)          1296      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 640, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 640, 32)           2592      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 320, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 320, 32)           5152      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 80, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 80, 64)            10304     \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 40, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 40, 64)            12352     \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 20, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 20, 64)            12352     \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 10, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 10, 64)            12352     \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 10, 128)           98432     \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 5, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                3250      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 183,762\n",
      "Trainable params: 183,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392e883a",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d310ce3",
   "metadata": {},
   "source": [
    "## Step1. Import WandB and Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3860e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkyulee\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f70dc",
   "metadata": {},
   "source": [
    "## Step2. Set x, y, model and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weight = {0:1, 1:10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28e16ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/Kyulee/wandb/run-20220617_003445-1ddemb6z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kyulee/PTB-XL/runs/1ddemb6z\" target=\"_blank\">laced-glade-7</a></strong> to <a href=\"https://wandb.ai/kyulee/PTB-XL\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 5120, 8)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 5120, 16)          912       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 2560, 16)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 2560, 16)          1296      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 640, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 640, 32)           2592      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 320, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 320, 32)           5152      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 80, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 80, 64)            10304     \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 40, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 40, 64)            12352     \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 20, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 20, 64)            12352     \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 10, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 10, 64)            12352     \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 10, 128)           98432     \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 5, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                3250      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 183,762\n",
      "Trainable params: 183,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = '220617_0935'\n",
    "model_path = os.path.join('ami_model', model_name + '_bestmodel.h5')\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=model_path,\n",
    "                                                monitor='val_accuracy',\n",
    "                                                verbose=1,\n",
    "                                                save_weights_only=False,\n",
    "                                                save_best_only=True,\n",
    "                                                mode='auto',\n",
    "                                                save_freq='epoch')\n",
    "\n",
    "run = wandb.init(project='PTB-XL', entity='kyulee', \n",
    "                 config={\n",
    "                     #'class_weight': '{0:1, 1:10}', \n",
    "                     'batch_size':256, \n",
    "                     'epochs':50,\n",
    "                     'loss_function':'binary_crossentropy', \n",
    "                     'architecture':'simple_Attia', \n",
    "                 })\n",
    "\n",
    "config = wandb.config\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss=config.loss_function, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad4b2c61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.3938 - accuracy: 0.0560\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.41620, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 10s 130ms/step - loss: 0.3938 - accuracy: 0.0560 - val_loss: 0.0992 - val_accuracy: 0.4162 - _timestamp: 1655426114.0000 - _runtime: 29.0000\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1302 - accuracy: 0.2625\n",
      "Epoch 00002: val_accuracy did not improve from 0.41620\n",
      "51/51 [==============================] - 3s 50ms/step - loss: 0.1302 - accuracy: 0.2625 - val_loss: 0.0864 - val_accuracy: 0.4162 - _timestamp: 1655426117.0000 - _runtime: 32.0000\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1075 - accuracy: 0.3630\n",
      "Epoch 00003: val_accuracy did not improve from 0.41620\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 0.1075 - accuracy: 0.3630 - val_loss: 0.0854 - val_accuracy: 0.4162 - _timestamp: 1655426119.0000 - _runtime: 34.0000\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.3889\n",
      "Epoch 00004: val_accuracy did not improve from 0.41620\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 0.0977 - accuracy: 0.3889 - val_loss: 0.0787 - val_accuracy: 0.4162 - _timestamp: 1655426121.0000 - _runtime: 36.0000\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.4080\n",
      "Epoch 00005: val_accuracy improved from 0.41620 to 0.45740, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 0.0910 - accuracy: 0.4080 - val_loss: 0.0750 - val_accuracy: 0.4574 - _timestamp: 1655426124.0000 - _runtime: 39.0000\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.4214\n",
      "Epoch 00006: val_accuracy did not improve from 0.45740\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 0.0874 - accuracy: 0.4214 - val_loss: 0.0749 - val_accuracy: 0.4476 - _timestamp: 1655426126.0000 - _runtime: 41.0000\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.4278\n",
      "Epoch 00007: val_accuracy improved from 0.45740 to 0.46578, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 0.0842 - accuracy: 0.4278 - val_loss: 0.0725 - val_accuracy: 0.4658 - _timestamp: 1655426129.0000 - _runtime: 44.0000\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 0.4388\n",
      "Epoch 00008: val_accuracy improved from 0.46578 to 0.48673, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 0.0822 - accuracy: 0.4388 - val_loss: 0.0716 - val_accuracy: 0.4867 - _timestamp: 1655426131.0000 - _runtime: 46.0000\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.4430\n",
      "Epoch 00009: val_accuracy did not improve from 0.48673\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 0.0804 - accuracy: 0.4430 - val_loss: 0.0703 - val_accuracy: 0.4818 - _timestamp: 1655426134.0000 - _runtime: 49.0000\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.4526\n",
      "Epoch 00010: val_accuracy did not improve from 0.48673\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 0.0790 - accuracy: 0.4526 - val_loss: 0.0698 - val_accuracy: 0.4721 - _timestamp: 1655426136.0000 - _runtime: 51.0000\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.4563\n",
      "Epoch 00011: val_accuracy improved from 0.48673 to 0.50070, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 49ms/step - loss: 0.0774 - accuracy: 0.4563 - val_loss: 0.0682 - val_accuracy: 0.5007 - _timestamp: 1655426138.0000 - _runtime: 53.0000\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.4681\n",
      "Epoch 00012: val_accuracy did not improve from 0.50070\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 0.0755 - accuracy: 0.4681 - val_loss: 0.0691 - val_accuracy: 0.4749 - _timestamp: 1655426141.0000 - _runtime: 56.0000\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 0.4679\n",
      "Epoch 00013: val_accuracy improved from 0.50070 to 0.50279, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 0.0762 - accuracy: 0.4679 - val_loss: 0.0659 - val_accuracy: 0.5028 - _timestamp: 1655426143.0000 - _runtime: 58.0000\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.4834\n",
      "Epoch 00014: val_accuracy did not improve from 0.50279\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 0.0731 - accuracy: 0.4834 - val_loss: 0.0686 - val_accuracy: 0.4784 - _timestamp: 1655426146.0000 - _runtime: 61.0000\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0721 - accuracy: 0.4907\n",
      "Epoch 00015: val_accuracy improved from 0.50279 to 0.51816, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 0.0721 - accuracy: 0.4907 - val_loss: 0.0644 - val_accuracy: 0.5182 - _timestamp: 1655426148.0000 - _runtime: 63.0000\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.4962\n",
      "Epoch 00016: val_accuracy did not improve from 0.51816\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 0.0709 - accuracy: 0.4962 - val_loss: 0.0640 - val_accuracy: 0.5154 - _timestamp: 1655426150.0000 - _runtime: 65.0000\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.5020\n",
      "Epoch 00017: val_accuracy improved from 0.51816 to 0.53003, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 49ms/step - loss: 0.0700 - accuracy: 0.5020 - val_loss: 0.0630 - val_accuracy: 0.5300 - _timestamp: 1655426153.0000 - _runtime: 68.0000\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.5126\n",
      "Epoch 00018: val_accuracy improved from 0.53003 to 0.53422, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 0.0689 - accuracy: 0.5126 - val_loss: 0.0634 - val_accuracy: 0.5342 - _timestamp: 1655426155.0000 - _runtime: 70.0000\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 0.5232\n",
      "Epoch 00019: val_accuracy improved from 0.53422 to 0.54260, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 0.0677 - accuracy: 0.5232 - val_loss: 0.0633 - val_accuracy: 0.5426 - _timestamp: 1655426158.0000 - _runtime: 73.0000\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.5236\n",
      "Epoch 00020: val_accuracy did not improve from 0.54260\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 0.0671 - accuracy: 0.5236 - val_loss: 0.0615 - val_accuracy: 0.5426 - _timestamp: 1655426160.0000 - _runtime: 75.0000\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.5348\n",
      "Epoch 00021: val_accuracy improved from 0.54260 to 0.55517, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 0.0666 - accuracy: 0.5348 - val_loss: 0.0609 - val_accuracy: 0.5552 - _timestamp: 1655426163.0000 - _runtime: 78.0000\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.5404\n",
      "Epoch 00022: val_accuracy improved from 0.55517 to 0.57193, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 49ms/step - loss: 0.0658 - accuracy: 0.5404 - val_loss: 0.0602 - val_accuracy: 0.5719 - _timestamp: 1655426165.0000 - _runtime: 80.0000\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.5571\n",
      "Epoch 00023: val_accuracy did not improve from 0.57193\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 0.0641 - accuracy: 0.5571 - val_loss: 0.0601 - val_accuracy: 0.5649 - _timestamp: 1655426167.0000 - _runtime: 82.0000\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.5602\n",
      "Epoch 00024: val_accuracy improved from 0.57193 to 0.57751, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 49ms/step - loss: 0.0639 - accuracy: 0.5602 - val_loss: 0.0595 - val_accuracy: 0.5775 - _timestamp: 1655426170.0000 - _runtime: 85.0000\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.5709\n",
      "Epoch 00025: val_accuracy improved from 0.57751 to 0.58450, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 49ms/step - loss: 0.0630 - accuracy: 0.5709 - val_loss: 0.0591 - val_accuracy: 0.5845 - _timestamp: 1655426172.0000 - _runtime: 87.0000\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.5798\n",
      "Epoch 00026: val_accuracy improved from 0.58450 to 0.58799, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 3s 49ms/step - loss: 0.0627 - accuracy: 0.5798 - val_loss: 0.0586 - val_accuracy: 0.5880 - _timestamp: 1655426175.0000 - _runtime: 90.0000\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.5856\n",
      "Epoch 00027: val_accuracy improved from 0.58799 to 0.58869, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 0.0616 - accuracy: 0.5856 - val_loss: 0.0585 - val_accuracy: 0.5887 - _timestamp: 1655426177.0000 - _runtime: 92.0000\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.5844\n",
      "Epoch 00028: val_accuracy improved from 0.58869 to 0.58939, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 0.0612 - accuracy: 0.5844 - val_loss: 0.0588 - val_accuracy: 0.5894 - _timestamp: 1655426180.0000 - _runtime: 95.0000\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.5908\n",
      "Epoch 00029: val_accuracy improved from 0.58939 to 0.59637, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 0.0606 - accuracy: 0.5908 - val_loss: 0.0582 - val_accuracy: 0.5964 - _timestamp: 1655426182.0000 - _runtime: 97.0000\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.5933\n",
      "Epoch 00030: val_accuracy did not improve from 0.59637\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 0.0600 - accuracy: 0.5933 - val_loss: 0.0600 - val_accuracy: 0.5538 - _timestamp: 1655426185.0000 - _runtime: 100.0000\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.5955\n",
      "Epoch 00031: val_accuracy did not improve from 0.59637\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 0.0599 - accuracy: 0.5955 - val_loss: 0.0589 - val_accuracy: 0.5922 - _timestamp: 1655426187.0000 - _runtime: 102.0000\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.5972\n",
      "Epoch 00032: val_accuracy did not improve from 0.59637\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 0.0587 - accuracy: 0.5972 - val_loss: 0.0584 - val_accuracy: 0.5747 - _timestamp: 1655426189.0000 - _runtime: 104.0000\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.5996\n",
      "Epoch 00033: val_accuracy improved from 0.59637 to 0.60056, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 0.0590 - accuracy: 0.5996 - val_loss: 0.0582 - val_accuracy: 0.6006 - _timestamp: 1655426192.0000 - _runtime: 107.0000\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.6085\n",
      "Epoch 00034: val_accuracy improved from 0.60056 to 0.60475, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 0.0571 - accuracy: 0.6085 - val_loss: 0.0582 - val_accuracy: 0.6047 - _timestamp: 1655426194.0000 - _runtime: 109.0000\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.6104\n",
      "Epoch 00035: val_accuracy improved from 0.60475 to 0.61592, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 0.0575 - accuracy: 0.6104 - val_loss: 0.0584 - val_accuracy: 0.6159 - _timestamp: 1655426197.0000 - _runtime: 112.0000\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.6210\n",
      "Epoch 00036: val_accuracy improved from 0.61592 to 0.61732, saving model to ami_model/220617_0935_bestmodel.h5\n",
      "51/51 [==============================] - 2s 49ms/step - loss: 0.0557 - accuracy: 0.6210 - val_loss: 0.0576 - val_accuracy: 0.6173 - _timestamp: 1655426199.0000 - _runtime: 114.0000\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.6166\n",
      "Epoch 00037: val_accuracy did not improve from 0.61732\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 0.0560 - accuracy: 0.6166 - val_loss: 0.0576 - val_accuracy: 0.5992 - _timestamp: 1655426202.0000 - _runtime: 117.0000\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.6179\n",
      "Epoch 00038: val_accuracy did not improve from 0.61732\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 0.0555 - accuracy: 0.6179 - val_loss: 0.0585 - val_accuracy: 0.5880 - _timestamp: 1655426204.0000 - _runtime: 119.0000\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.6289\n",
      "Epoch 00039: val_accuracy did not improve from 0.61732\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 0.0547 - accuracy: 0.6289 - val_loss: 0.0606 - val_accuracy: 0.5901 - _timestamp: 1655426206.0000 - _runtime: 121.0000\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.6240\n",
      "Epoch 00040: val_accuracy did not improve from 0.61732\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 0.0546 - accuracy: 0.6240 - val_loss: 0.0579 - val_accuracy: 0.6047 - _timestamp: 1655426209.0000 - _runtime: 124.0000\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.6328\n",
      "Epoch 00041: val_accuracy did not improve from 0.61732\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 0.0529 - accuracy: 0.6328 - val_loss: 0.0584 - val_accuracy: 0.6103 - _timestamp: 1655426211.0000 - _runtime: 126.0000\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.6307\n",
      "Epoch 00042: val_accuracy did not improve from 0.61732\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 0.0529 - accuracy: 0.6307 - val_loss: 0.0597 - val_accuracy: 0.6041 - _timestamp: 1655426213.0000 - _runtime: 128.0000\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.6379\n",
      "Epoch 00043: val_accuracy did not improve from 0.61732\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 0.0515 - accuracy: 0.6379 - val_loss: 0.0627 - val_accuracy: 0.5915 - _timestamp: 1655426216.0000 - _runtime: 131.0000\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.6312\n",
      "Epoch 00044: val_accuracy did not improve from 0.61732\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 0.0523 - accuracy: 0.6312 - val_loss: 0.0586 - val_accuracy: 0.5985 - _timestamp: 1655426218.0000 - _runtime: 133.0000\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.6397\n",
      "Epoch 00045: val_accuracy did not improve from 0.61732\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 0.0510 - accuracy: 0.6397 - val_loss: 0.0607 - val_accuracy: 0.5838 - _timestamp: 1655426220.0000 - _runtime: 135.0000\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.6400\n",
      "Epoch 00046: val_accuracy did not improve from 0.61732\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 0.0505 - accuracy: 0.6400 - val_loss: 0.0625 - val_accuracy: 0.5992 - _timestamp: 1655426223.0000 - _runtime: 138.0000\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.6450\n",
      "Epoch 00047: val_accuracy did not improve from 0.61732\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 0.0502 - accuracy: 0.6450 - val_loss: 0.0618 - val_accuracy: 0.5887 - _timestamp: 1655426225.0000 - _runtime: 140.0000\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.6462\n",
      "Epoch 00048: val_accuracy did not improve from 0.61732\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 0.0496 - accuracy: 0.6462 - val_loss: 0.0607 - val_accuracy: 0.6082 - _timestamp: 1655426227.0000 - _runtime: 142.0000\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.6476\n",
      "Epoch 00049: val_accuracy did not improve from 0.61732\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 0.0491 - accuracy: 0.6476 - val_loss: 0.0700 - val_accuracy: 0.6054 - _timestamp: 1655426230.0000 - _runtime: 145.0000\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.6487\n",
      "Epoch 00050: val_accuracy did not improve from 0.61732\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 0.0487 - accuracy: 0.6487 - val_loss: 0.0601 - val_accuracy: 0.5985 - _timestamp: 1655426232.0000 - _runtime: 147.0000\n",
      "Epochs=50, Train accuracy=0.64869, Validation accuracy=0.61732 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='2.229 MB of 2.229 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▂▃▃▃▄▃▄▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇██▇▇▇██▇▇▇▇█▇</td></tr><tr><td>val_loss</td><td>█▆▆▅▄▄▃▃▃▃▂▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▁▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.64869</td></tr><tr><td>best_epoch</td><td>35</td></tr><tr><td>best_val_loss</td><td>0.05755</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.0487</td></tr><tr><td>val_accuracy</td><td>0.59846</td></tr><tr><td>val_loss</td><td>0.06005</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">laced-glade-7</strong>: <a href=\"https://wandb.ai/kyulee/PTB-XL/runs/1ddemb6z\" target=\"_blank\">https://wandb.ai/kyulee/PTB-XL/runs/1ddemb6z</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220617_003445-1ddemb6z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_split=0.1, \n",
    "                    batch_size=config.batch_size, \n",
    "                    epochs=config.epochs,\n",
    "                    callbacks=[checkpoint,WandbCallback()],\n",
    "                    #class_weight = class_weight,\n",
    "                    verbose=1)\n",
    "\n",
    "print(\"Epochs={0:d}, Train accuracy={1:.5f}, Validation accuracy={2:.5f} \\n\".format(\n",
    "    config.epochs, max(history.history['accuracy']),max(history.history['val_accuracy']) ))\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fca955",
   "metadata": {},
   "source": [
    "## Step3. Review Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fd71330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy 비교\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['training', 'validation'], loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33db3b53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss 비교\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['training', 'validation'], loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3c8834",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c027a3",
   "metadata": {},
   "source": [
    "## Step1. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b4eea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# make a prediction on the test set\n",
    "y_proba = model.predict(x_test)\n",
    "# round probabilities to class labels\n",
    "y_pred = y_proba.round()\n",
    "# calculate accuracy\n",
    "acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "914edbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4818435754189944"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7319fc",
   "metadata": {},
   "source": [
    "## Step2. Interpret Test Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05b2dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3df3f070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2015002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91cb42b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1AVB       0.00      0.00      0.00       167\n",
      "        2AVB       0.00      0.00      0.00         4\n",
      "        3AVB       0.00      0.00      0.00         2\n",
      "        AFIB       0.00      0.00      0.00        11\n",
      "        AFLT       0.00      0.00      0.00        16\n",
      "        ALMI       0.00      0.00      0.00        41\n",
      "         AMI       0.00      0.00      0.00        27\n",
      "       ANEUR       0.00      0.00      0.00         1\n",
      "        ASMI       0.72      0.35      0.47       311\n",
      "        BIGU       0.00      0.00      0.00         4\n",
      "       CLBBB       0.94      0.84      0.89       106\n",
      "       CRBBB       0.86      0.76      0.80       103\n",
      "         DIG       0.00      0.00      0.00        27\n",
      "          EL       0.00      0.00      0.00         1\n",
      "       ILBBB       0.00      0.00      0.00        15\n",
      "        ILMI       0.00      0.00      0.00        69\n",
      "         IMI       0.00      0.00      0.00       206\n",
      "       INJAL       0.00      0.00      0.00        29\n",
      "       INJAS       0.00      0.00      0.00        43\n",
      "       INJIL       0.00      0.00      0.00         5\n",
      "       INJIN       0.00      0.00      0.00         3\n",
      "       INJLA       0.00      0.00      0.00         1\n",
      "       IPLMI       0.00      0.00      0.00         7\n",
      "        IPMI       0.00      0.00      0.00         6\n",
      "       IRBBB       0.57      0.50      0.53       204\n",
      "       ISCAL       0.00      0.00      0.00       118\n",
      "       ISCAN       0.00      0.00      0.00         7\n",
      "       ISCAS       0.00      0.00      0.00        28\n",
      "       ISCIL       0.00      0.00      0.00        28\n",
      "       ISCIN       0.00      0.00      0.00        34\n",
      "       ISCLA       0.00      0.00      0.00        18\n",
      "        ISC_       0.77      0.36      0.49       227\n",
      "        IVCD       0.00      0.00      0.00       154\n",
      "        LAFB       0.82      0.53      0.64       339\n",
      "     LAO_LAE       0.00      0.00      0.00        50\n",
      "         LMI       0.00      0.00      0.00         6\n",
      "       LNGQT       0.00      0.00      0.00        25\n",
      "        LPFB       0.00      0.00      0.00        40\n",
      "         LVH       0.58      0.19      0.29       208\n",
      "         NDT       0.52      0.44      0.47       365\n",
      "        NORM       0.89      0.84      0.86      1422\n",
      "        NST_       0.00      0.00      0.00       117\n",
      "         PAC       0.00      0.00      0.00         5\n",
      "        PACE       0.92      0.85      0.89        41\n",
      "        PSVT       0.00      0.00      0.00        10\n",
      "         PVC       0.94      0.35      0.51       205\n",
      "     RAO_RAE       0.00      0.00      0.00        17\n",
      "         RVH       0.00      0.00      0.00         9\n",
      "       SEHYP       0.00      0.00      0.00         5\n",
      "         WPW       0.00      0.00      0.00         9\n",
      "\n",
      "   micro avg       0.80      0.44      0.56      4896\n",
      "   macro avg       0.17      0.12      0.14      4896\n",
      "weighted avg       0.57      0.44      0.48      4896\n",
      " samples avg       0.60      0.53      0.55      4896\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=class_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa5bae5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a49c18",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b3c1c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "from keras.models import load_model\n",
    "model.save('/home/ubuntu/Kyulee/'+model_name+'_bestmodel.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
